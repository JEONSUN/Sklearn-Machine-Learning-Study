{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 만약 훈련 데이터가 한 번에 준비되는 것이 아닌 조금씩 전달된다면?\n",
    "\n",
    "데이터가 쌓일때까지 기다리기도 어렵게 도착하는대로 솔루션을 제시해야한다면? \n",
    "\n",
    "***\n",
    "해결방안1. 기존의 훈련 데이터에 새로운 데이터를 추가하여 모델을 매일매일 훈련한다<Br>\n",
    "단점: 시간이 지날수록 데이터가 늘어난다. 몇년이 지나면...  지속 가능한 방법은 아니다.\n",
    "    \n",
    "\n",
    "해결방안2. 새로운 데이터를 추가할 때 이전 데이터를 버림으로써 훈련 데이터 크기를 일정하게 유지한다.<br>\n",
    "단점: 데이터를 버릴 때 다른 데이터에 없는 레이블이 들어가 있으면 문제가 생긴다.\n",
    "    \n",
    "***    \n",
    "**앞서 훈련한 모델을 버리지 않고 새로운 데이터에 대해서만 조금씩 더 훈련할 필요가 있다.... 이렇게 한다면 훈련에 사용한 데이터를 모두 유지할 필요도 없고 앞서 학습한 내용을 까먹을 일도 없다.**\n",
    "    \n",
    "\n",
    "이런 식의 훈련 방식을 **점진적 학습**이라고 부르며 대표적인 점진적 학습 알고리즘은 **확률적 경사 하강법(Stochastic Gradient Descent)**가 있다.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 확률적 경사 하강법\n",
    "\n",
    "- 훈련세트에서 랜덤하게 하나의 샘플을 고르는 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/fish.csv', encoding = 'CP949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['Species', 'Weight', 'Length1', 'Length2', 'Length3', 'Height',\n",
    "       'Width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data[['Species']].to_numpy()\n",
    "data = data.drop(['Species'], axis = 1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(data,target, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119, 6)\n",
      "(40, 6)\n",
      "(119,)\n",
      "(40,)\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.flatten()\n",
    "y_test =  y_test.flatten()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(x_train)\n",
    "train_scaled = ss.transform(x_train)\n",
    "test_scaled = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7983193277310925\n",
      "0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    }
   ],
   "source": [
    "# 손실함수 log, 훈련셋 10회 반복\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(loss = 'log', max_iter = 10, random_state = 42)\n",
    "sgd.fit(train_scaled, y_train)\n",
    "print(sgd.score(train_scaled, y_train))\n",
    "print(sgd.score(test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9159663865546218\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "# 너무 적은 반복으로 경고 발생, 100회 실시\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(loss = 'log', max_iter = 100, random_state = 42)\n",
    "sgd.fit(train_scaled, y_train)\n",
    "print(sgd.score(train_scaled, y_train))\n",
    "print(sgd.score(test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
