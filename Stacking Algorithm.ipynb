{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스태킹 알고리즘/스태킹 앙상블\n",
    "\n",
    "- 단순 회귀나 랜덤포레스트를 이용할 경우 기존의 데이터에서 벗어난 범위의 예측을 진행할 경우 **외삽**문제가 발생함.\n",
    "\n",
    "\n",
    "- 이럴때 사용할 수 있는게 스태킹 알고리즘이나 딥러닝 모델을 사용함.\n",
    "\n",
    "\n",
    "- 스태킹 알고리즘 단계\n",
    "***\n",
    "1. n개의 모델로 학습 모델을 생성(기존의 회귀, rbf 등등...) \n",
    "\n",
    "2. n개의 모델에서 생성한 학습 모델을 기반으로 다시 최종 예측값(meta model) 생성\n",
    "***\n",
    "\n",
    "- 배깅과 비슷한 과정을 거치지만 최종 예측값을 생성한다는 것에서 차이점이 있음.\n",
    "\n",
    "- 이렇게 적용한다고 하여 반드시 성능 향상을 이끌어낸다는 보장은 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본적인 스태킹 예제\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "X_data = cancer_data.data\n",
    "y_label = cancer_data.target\n",
    "\n",
    "# 데이터 분리\n",
    "X_training , X_testing , y_training , y_testing = train_test_split(X_data , y_label , test_size=0.2 , random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30)\n",
      "(114, 30)\n",
      "(455,)\n",
      "(114,)\n"
     ]
    }
   ],
   "source": [
    "print(X_training.shape)\n",
    "print(X_testing.shape)\n",
    "print(y_training.shape)\n",
    "print(y_testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 ML 모델을 위한 Classifier 생성.\n",
    "knn_clf  = KNeighborsClassifier(n_neighbors=4) #K최근접이웃\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)#랜덤포레스트\n",
    "dt_clf = DecisionTreeClassifier() #결정트리\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100) #아다부스트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개별 모델들을 학습. \n",
    "knn_clf.fit(X_training, y_training)  \n",
    "rf_clf.fit(X_training , y_training)  \n",
    "dt_clf.fit(X_training , y_training)\n",
    "ada_clf.fit(X_training, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 개별 모델들이 각자 반환하는 예측 데이터 셋을 생성하고 개별 모델의 정확도 측정. \n",
    "knn_pred = knn_clf.predict(X_testing)\n",
    "rf_pred = rf_clf.predict(X_testing)\n",
    "dt_pred = dt_clf.predict(X_testing)\n",
    "ada_pred = ada_clf.predict(X_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 정확도: 0.9211\n",
      "랜덤 포레스트 정확도: 0.9649\n",
      "결정 트리 정확도: 0.9123\n",
      "에이다부스트 정확도: 0.9561 :\n"
     ]
    }
   ],
   "source": [
    "print('KNN 정확도: {0:.4f}'.format(accuracy_score(y_testing, knn_pred)))\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy_score(y_testing, rf_pred)))\n",
    "print('결정 트리 정확도: {0:.4f}'.format(accuracy_score(y_testing, dt_pred)))\n",
    "print('에이다부스트 정확도: {0:.4f} :'.format(accuracy_score(y_testing, ada_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4가지 모델중 랜덤 포레스트의 정확도가 가장 높게 나왔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스태킹 알고리즘은 4가지 모델의 결과값을 최종 모델의 새로운 인풋으로 전환함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4가지 모델 결과값\n",
    "pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 값을 4개의 변수로 전환\n",
    "pred = np.transpose(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 Stacking 모델을 위한 Classifier생성. \n",
    "lr_final = LogisticRegression(C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도: 0.9649\n"
     ]
    }
   ],
   "source": [
    "# 최종 모델 정확도\n",
    "lr_final.fit(pred, y_testing)\n",
    "final = lr_final.predict(pred)\n",
    "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_testing , final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개별 모델과 같은 결과가 나왔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스태킹은 학습 데이터에 한하여 2번의 예측을 진행하므로 성능면에서 좋은 결과를 얻을 수 있으나, 학습 데이터에 분산이 큰 데이터가 있을 경우 성능이 떨어질 수가 있으며, 과적합에 대한 위험도를 배제할 수가 없다.\n",
    "\n",
    "이럴때 CV를 포함한 스태킹 알고리즘을 실시한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
