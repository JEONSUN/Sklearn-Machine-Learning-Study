{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 핸즈온 머신러닝 7장 연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 정확히 같은 훈련 데이터로 다섯 개의 다른 모델을 훈련시켜서 모두 95% 정확도를 얻었다면 이 모델들을 연결하여 더 좋은 결과를 얻을 수있을까요? 가능하다면 어떻게 해야 할까요? 그렇지 않다면 왜일까요?\n",
    "\n",
    "\n",
    "좋은 결과가 나올 것이다. 각 분류기가 약한 학습기여도 충분하게 많고 다양하다면 앙상블은 높은 정확도를 가진 강한 학습기가 될 수 있기 때문이다.\n",
    "모델이 서로 독립적이거나, 다양하거나, 다른 훈련 샘플에서 훈련되었다면 앙상블은 더더욱 좋다. 그렇지 않더라도 모델이 서로 다르면 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 직접 투표와 간접 투표 분류기 사이의 차이점은 무엇일까요?\n",
    "\n",
    "직접 투표는 여러 분류기에서 나온 결과들 중 많은 수를 차지한 예측값을 그대로 사용한다. (횟수 중심, 다수결)\n",
    "\n",
    "간접 투표는 여러 분류기에서 나온 예측들의 평균을 계산하여 가장 높은 확률을 가진 클래스를 예측값으로 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배깅 앙상블의 훈련을 여러 대의 서버에 분산시켜 속도를 높일 수 있을까요? 페이스팅 앙상블, 부스팅 앙상블, 랜덤 포레스트, 스태킹 앙상블의 경우는 어떨까요?\n",
    "\n",
    "배깅, 페이스팅, 랜덤 포레스트 앙상블의 예측기는 서로 독립이므로 여러 대의 서버에 분산시켜 훈련 시킬 경우 앙상블의 훈련 속도를 높일 수 있다.\n",
    "\n",
    "그러나 부스팅은 이전의 모델을 보완해나가면서 만들어지기때문에 훈련이 순차적이어야하기에 분산 시킨다고 얻는 효과가 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oob 평가의 장점은 무엇일까요?\n",
    "\n",
    "oob 평가는 각 예측기에 대한 어떤 샘플의 사용 유무를 평가할 때 사용된다. 선택되지 않은 샘플을 사용해서 평가하기에, 추가적인 검증 세트가 없어도 편향되지 않게 앙상블을 평가하도록 도와준다. 그러므로 더 많은 훈련 샘플을 사용하여 앙상블 모델의 성능을 향상시킬 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 무엇이 엑스트라 트리를 일반 랜덤 포레스트보다 더 무작위하게 만드나요? 추가적인 무작위성이 어떻게 도움이 될까요? 엑스트라 트리는 일반 랜덤 포레스트보다 느릴까요, 빠를까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 에이다부스트 앙상블이 훈련 데이터에 과소적합되었다면 어떤 매개변수를 어떻게 바꾸어야 할까요?\n",
    "\n",
    "학습기의 갯수(n_estimators)의 수를 증가시키거나, 규제 하이퍼파라미터를 감소시킨다. 학습률(learning_rate)를 증가시켜본다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그레디언트 부스팅 앙상블이 훈련 데이터에 과대적합되었다면 학습률을 높여야할까요, 낮춰야할까요?\n",
    "\n",
    "학습률을 낮춰야한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 데이터를 불러들여 훈련 세트, 검증 세트, 테스트 세트로 나눈다(훈련  : 50000/ 검증 : 10000/ 테스트 : 10000개) 그런 다음 랜덤 포레스트 분류기, 엑스트라 트리 분류기, SVM 분류기 같은 여러 종류의 분류기를 훈련시킨다. 그리고 검증 세트에서 개개의 분류기보다 더 높은 성능을 내도록 이들을 간접 또는 직접 투표 방법을 사용해 앙상블로 연결해보세요. 앙상블을 얻고나면 테스트 세트로 확인해보세요. 개개의 분류기와 비교해서 성능이 얼마나 향상되나요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist 불러오기\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set 10000개 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_val,X_test,y_train_val,y_test = train_test_split(mnist['data'],mnist['target'],test_size = 10000, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val set 10000개 분리\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train_val,y_train_val, test_size = 10000, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000,)\n",
      "(10000, 784)\n",
      "(10000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설정\n",
    "lsvm = SVC(max_iter = 1000, random_state = 42, probability = True, kernel = \"linear\") # 학습 반복횟수 1000번\n",
    "rand = RandomForestClassifier(n_estimators = 10,random_state = 42) # 예측기의 개수 = 10개\n",
    "extr = ExtraTreesClassifier(n_estimators = 10, random_state = 42)\n",
    "mlp = MLPClassifier() # 다중신경망 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 : SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=1000, probability=True, random_state=42,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 : RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "훈련 : ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "           oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "훈련 : MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "model = [lsvm,rand,extr,mlp]\n",
    "\n",
    "for i in model :\n",
    "    print(\"훈련 :\", i)\n",
    "    i.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.811\n",
      "정확도 : 0.9469\n",
      "정확도 : 0.9492\n",
      "정확도 : 0.9638\n"
     ]
    }
   ],
   "source": [
    "# val 검증\n",
    "for i in model :\n",
    "    y_pred = i.predict(X_val)\n",
    "    print(\"정확도 :\", accuracy_score(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능은 mlp, extr, rand, svm 순"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "models = [(\"LinearSVM\", lsvm),(\"ExtraTrees\",extr),(\"RandomForest\",rand),(\"MLPClassifier\",mlp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vot_clf = VotingClassifier(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vot 모델 적합\n",
    "vot_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vto_clf 스코어\n",
    "vot_clf.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[model.score for model in vot_clf.estimators_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간접투표\n",
    "# 이미 모델 훈련은 시켰기때문에 hard -> soft로 변환\n",
    "vot_clf.voting = 'soft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vot_clf.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 점수 예측\n",
    "[model.score(X_test,y_test) for model in vot_clf.estimators_]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
